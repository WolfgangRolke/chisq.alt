---
title: Calculations for Chisquare with Alternative
header-includes: \usepackage{color}
                 \usepackage{float}
output:
  html_document: default
  pdf_document:
    fig_caption: no
---

```{r, echo=FALSE}
tmp <- try(library(chisqalt), silent=TRUE)
if(substring(tmp[1], 1, 5)=="Error") {
  cat("Download library chisqalt from https://github.com/WolfgangRolke/chisqalt\n")
} else {library(chisqalt)}  
library(knitr)
opts_chunk$set(echo=FALSE, 
               message=FALSE, 
               warning=FALSE,
               error=TRUE)
```

To run theses calculations you need the R library *chisqalt*. 

```{r}
B <- 10000 # Number of simulation runs
custom.col <- c("#4E84C4", "#C4961A",
                "#D16103", "#FFDB6D",
                "#52854C", "#293352",
                "#3399FF", "#00FF99", "#FF00CC")
# Colors for graphs (not used)
custom.shape <- c(20, 0:7)
Methods <- c("RG", "Equal Prob",
    "Equal Size", "Histogram",  "KS", "AD",
    "ZK", "ZA", "ZC")
bttr <- expression(RG ~ chi^2)
```


## Why maximum likelihood estimation doesn't work 

Consider the normal mixture model, specifically

$X \sim \frac13 N(0, 1) +\frac23 N(5,2)$

We will use both maximum likelihood estimation and minimum chisquare to estimate parameters and do the chisquare test. In all cases we use 10 equal probability bins. We repeat this B=10000 times and find the proportion of p values less than $5\%$.

```{r}
ndata <- 1000 # Size of data set
nbins <- 10 # Number of bins
set.seed(1113)
```

```{r make.funs}
make.funs <- function() {
  rnull <- function(n) {
    Z <- sample(c(TRUE, FALSE), size=n, 
        replace=TRUE, prob=c(1/3, 2/3))
    rnorm(n, ifelse(Z, 0, 5),
        ifelse(Z, 1, 2))
  }
  pnull <- function(x, p) {
    p[1]*pnorm(x, p[2], p[3]) + 
    (1-p[1])*pnorm(x, p[4], p[5])  
  }

  est.mle <- function(x) {
    loglike <- function(p, x) {
      -sum(log(p[1]*dnorm(x, p[2], p[3]) + 
     (1-p[1])*dnorm(x, p[4], p[5])))
    }
    start <- c(1/3, 0, 1, 5, 2)
    lower <- c(0, -1, 0.5, 2, 0.5)
    upper <- c(1, 1, 3, 8, 6)
    optim(start, loglike, lower=lower, 
        upper=upper, x=x)$par
  }
  est.minchi <- function(O) {
    chi <- function(par, O) {
      E <-  ndata*diff(pnull(bins, par))
      E[E<0.01] <- 0.01
      sum((O-E)^2/E)
    }
    start <- c(1/3, 0, 1, 5, 2)
    lower <- c(0, -1, 0.5, 2, 0.5)
    upper <- c(1, 1, 3, 8, 6)
    par <- optim(start, chi, lower=lower, 
        upper=upper, O=O)$par
  }
  list(rnull=rnull, pnull=pnull, 
      est.mle=est.mle,
      est.minchi=est.minchi) 
} 
```


```{r make.bins}
z <- make.funs()$rnull(1e6)
bins <- quantile(z, seq(0, 1, length=nbins+1))
bins[c(1, nbins+1)] <- c(-Inf, Inf)
assign("bins", bins)
```


```{r mle.chisq}
mle.chisq <-  function() {
  funs <- make.funs()  
  pvals <- matrix(0, B, 2)
  for(i in 1:B) {
    x <- funs$rnull(ndata)
    mle <- funs$est.mle(x)
    E <- ndata*diff(funs$pnull(bins, mle))
    df <- length(E)-1-5
    O <- hist(x, breaks=bins, 
              plot = FALSE)$counts
    pvals[i, 1] <- 
       1-pchisq(sum((O-E)^2/E), df)
    minchi <- funs$est.minchi(O)
    E <- ndata*diff(funs$pnull(bins, minchi))
    pvals[i, 2] <- 
      1-pchisq(sum((O-E)^2/E), df)
  }
  out <- c(sum(pvals[, 1]<0.05), 
    sum(pvals[, 2]<0.05))/B
  names(out) <- c("MLE", "MinChi")
  out
}
```

```{r mle, cache=TRUE, error=TRUE}
mle.chisq()
```

## Number of bins

```{r fig1, cache=TRUE}
case <- list(
  param = NULL,
  B = B,
  alpha = 0.05,
  n = 1000, # sample size
  dnull = function(x, param) dunif(x),  
  pnull = function(x, param) punif(x),
  qnull = function(x, param) qunif(x),
  rnull = function(n) runif(n),
  palt = function(x) plinear(x, 0.2),
  ralt = function(n) rlinear(n, 0.2),
  LR = c(0, 1)
)
case <- make.case(case)
k <- 2:21
n <- c(100, 250, 500, 1000, 2000)
out <- matrix(0, 5, 20)
dimnames(out) <- list(n, k)
for(j in seq_along(n)) {
  case$n <- n[j]
  for(i in seq_along(k))
    out[j, i] <- round(standard.chisq.power(case, k[i])$power[1]*100, 1)
}  
df <- data.frame(
  n=factor(rep(n, 20)),
  k=rep(k, each=5),
  Power=c(out))
```

```{r}
plt1 <- ggplot(data=df, 
               aes(k, Power, shape=n)) +
  geom_point() +
  labs(color='Sample Size')+
  xlab('Number of Bins')
print(plt1)
ggsave(paste0(getwd(), "/Computational Statistics/Fig1.eps"))
```

## Type of bins

```{r}
x <- seq(0, 1, length=250)
y1 <- dlinear(x, -0.5)
y2 <- dtexp(x, 1)
df <- data.frame(
  x=c(x,x),
  y=c(y1, y2),
  Model=rep(c("Linear", "Exponential"),
            each=250))
``` 


```{r fig2, cache=TRUE}
case <- list(
  param = NULL,
  B = B,
  alpha = 0.05,
  n = 10000, # sample size
  dnull = function(x, param) 
    dlinear(x, -0.5),  
  pnull = function(x, param) 
    plinear(x, -0.5),
  rnull = function(n) rlinear(n, -0.5),
  palt = function(x) ptexp(x, 1),
  ralt = function(n) rtexp(n, 1),
  LR = c(0, 1)
)
case <- make.case(case)
kappas <- seq(0, 1, length=5)
M <- matrix(0, 5, 20)
dimnames(M) <- list(kappas, 2:21)
P <- M
for(k in  1:20) {
  for(i in seq_along(kappas)) {
    M[i, k] <- minchi.alt(case=case,  
          k=k+1, kappa=kappas[i])$value
    P[i, k] <- standard.chisq.power(
      case=case,  k=k+1,
      kappa=kappas[i])$power
  }  
}
round(M, 2)
round(100*P, 1)
df <- data.frame(
  n = rep(2:21, 5),
  M=c(t(M)),
  Power=c(t(P)),
  kappa=factor(rep(kappas, each=20))
)
```

```{r}
plt2 <- ggplot(data=df, aes(n, M, shape=kappa)) +
  geom_point() + labs(x='Number of Bins')
plt2
ggsave(paste0(getwd(), "/Computational Statistics/Fig2.eps"))
plt3 <- ggplot(data=df, aes(n, Power, shape=kappa))+
  geom_point() + labs(x='Number of Bins')
plt3
ggsave(paste0(getwd(), "/Computational Statistics/Fig3.eps"))
```

## Normal(0,1) vs t(df)

```{r}
case <- list(
  param = NULL,
  B = B,
  n = 1000, # sample size
  alpha = 0.05,
  dnull = function(x, param) dnorm(x),  
  pnull = function(x, param) pnorm(x),
  rnull = function(n) rnorm(n),
  qnull = function(p) qnorm(p),  
  palt = function(x) pt(x, 1),
  ralt = function(n) rt(n, 1),
  LR = c(-Inf, Inf)
)
case <- make.case(case)
mle.fun <- function(x) c(0, 1)
```

-  Power vs. various alternatives:

```{r fig4, cache=TRUE}
rn <- 1

out <- matrix(0, 20, length(Methods))
rownames(out) <- paste("df =", 3*1:20)
colnames(out) <- Methods
for(i in 1:20) {
  case$palt <- function(x) pt(x, 3*i)
  case$ralt <- function(n) rt(n, 3*i)
  out[i, ] <- tests.power(case, mle.fun)
}  
out <- round(out*100, 1)
```


-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```

```{r}
colnames(out) <- Methods
df <- data.frame(
  x=rep(3*1:20, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
```

```{r}
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab("Degree of Freedom") +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig4.eps"))
all.cases <- out
```

-  Does $M_{k,\kappa}$ yield best power?

```{r fig4a, cache=TRUE}
case$palt <- function(x) pt(x, 15)
case <- make.case(case)
best <- RG.power(case)
Ks <- best$nbins + (-2):2
Ks <- Ks[Ks>1+length(case$param)]
kappa <- 0:4/4
out <- matrix(0, length(Ks), 5)
colnames(out) <- kappa
rownames(out) <- Ks
for(i in seq_along(Ks)) 
  out[i, ] <- standard.chisq.power(case, 
          k=Ks[i],  kappa=0:4/4,
          method=best$method)$power
unlist(best)
round(out*100, 1)
```

Yes!

-  Dependence on Sample Size

```{r fig4b, cache=TRUE}
rn <- 1
n <- c(100, 250, 500, 1000, 2000)
out <- matrix(0, 2, 5)
dimnames(out) <- list(c("nbins", "kappa"), n)
for(i in c(1, 10, 20)) {
  cat("df= ", 3*i, "\n")
  case$palt = function(x) pt(x, 3*i)
  case$ralt = function(n) rt(n, 3*i)
  for(j in seq_along(n)) {
    case$n <- n[j]
    out[, j] <- as.numeric(unlist(RG.power(case))[1:2])
  }
  print(out)
}
```


## Normal vs t(df)

```{r}
case <- list(
  param = c(0, 1),
  B = B,
  n = 1000, # sample size
  dnull = function(x, param) 
    dnorm(x, param[1], param[2]),  
  pnull = function(x, param) 
    pnorm(x, param[1], param[2]),  
  rnull = function(n) rnorm(n),
  qnull = function(p) qnorm(p), 
  palt = function(x) pt(x, 1),
  ralt = function(n) rt(n, 1),
  LR = c(-Inf, Inf)
)
case <- make.case(case)
mle.fun <- function(x) c(mean(x), sd(x))
```

-  Power vs. various alternatives:

```{r fig5, cache=TRUE}
rn <- 2
out <- matrix(0, 20, length(Methods))
rownames(out) <- paste("df =", 3*1:20)
colnames(out) <- Methods
for(i in 1:20) {
  case$palt <- function(x) pt(x, 3*i)
  case$ralt <- function(n) rt(n, 3*i)
  out[i, ] <- tests.power(case, est.mle=mle.fun)  
} 
out <- round(out*100, 1)
```



-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```

```{r}
colnames(out) <- Methods
df <- data.frame(
  x=rep(3*1:20, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab("Degree of Freedom") +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig5.eps"))
out
all.cases <- rbind(all.cases, out)
```


-  Does $M_{k,\kappa}$ yield best power?

```{r fig5a, cache=TRUE}
case$palt <- function(x) pt(x, 9)
case <- make.case(case)
best <- RG.power(case)
Ks <- best$nbins + (-2):2
Ks <- Ks[Ks>1+length(case$param)]
kappa <- 0:4/4
out <- matrix(0, length(Ks), 5)
colnames(out) <- kappa
rownames(out) <- Ks
for(i in seq_along(Ks)) 
     out[i, ] <- standard.chisq.power(case, 
          k=Ks[i],  kappa=kappa,
          method=best$method)$power
unlist(best)
round(out*100, 1)

```

Yes!

-  Dependence on Sample Size

```{r fig5b, cache=TRUE}
n <- c(100, 250, 500, 1000, 2000)
out <- matrix(0, 2, 5)
dimnames(out) <- list(c("nbins", "kappa"), n)
for(i in c(1, 10, 20)) {
  cat("df= ", 3*i, "\n")
  case$palt = function(x) pt(x, 3*i)
  case$ralt = function(n) rt(n, 3*i)
  for(j in seq_along(n)) {
    case$n <- n[j]
    out[, j] <- as.numeric(unlist(RG.power(case))[1:2])
  }
  print(out)
}
```


### Uniform[0,1] vs Linear

Here we have $H_0: F=U[0,1]$ vs $H_a: F=\text{Linear}(s)$.

```{r}
case <- list(
  param = NULL,
  B = B,
  n = 1000, # sample size
  dnull = function(x, param) 
    dunif(x),  
  pnull = function(x, param) 
    punif(x),  
  rnull = function(n) runif(n),
  qnull = function(p) p, 
  palt = function(x) plinear(x, 0.1),
  ralt = function(n) rlinear(n, 0.1),
  LR = c(0, 1)
)
case <- make.case(case)
```

-  Power vs. various alternatives:

```{r fig6, cache=TRUE}
rn <- 1
slope <- round(seq(0, 0.3, length=20), 2)
out <- matrix(0, 20, length(Methods))
rownames(out) <- paste("slope =", slope)
colnames(out) <- Methods
for(i in 1:20) {
  case$palt = function(x) 
    plinear(x, slope[i])
  case$ralt = function(n) 
    rlinear(n, slope[i])
  out[i, ] <- tests.power(case)  
} 
out <- round(out*100, 1)
```


-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```


```{r}
colnames(out) <- Methods
df <- data.frame(
  x=rep(slope, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab("Slope") +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig6.eps"))
all.cases <- rbind(all.cases, out)
```

-  Does $M_{k,\kappa}$ yield best power?

```{r fig6a, cache=TRUE}
case$palt = function(x) plinear(x, 0.14)
case$ralt = function(n) rlinear(n, 0.14)
case <- make.case(case)
best <- RG.power(case)
Ks <- best$nbins + (-2):2
Ks <- Ks[Ks>1+length(case$param)]
kappa <- 0:4/4
out <- matrix(0, length(Ks), 5)
colnames(out) <- kappa
rownames(out) <- Ks
for(i in seq_along(Ks)) 
     out[i, ] <- standard.chisq.power(case, 
          k=Ks[i],  kappa=kappa,
          method=best$method)$power
unlist(best)
round(out*100, 1)

```

Yes (within simulation error)!


-  Dependence on Sample Size

```{r fig6b, cache=TRUE}
n <- c(100, 250, 500, 1000, 2000)
out <- matrix(0, 2, 5)
dimnames(out) <- list(c("nbins", "kappa"), n)
for(i in c(1, 10, 20)) {
  cat("slope= ", slope[i],"\n")
  case$palt <- function(x) plinear(x, slope[i])
  case$ralt <- function(n) rlinear(n, slope[i])
  for(j in seq_along(n)) {
    case$n <- n[j]
    out[, j] <- as.numeric(unlist(RG.power(case))[1:2])
  }
  print(out)
}  
```

### Exponential  vs Exponential(1)+Normal(1.5, sigma)


```{r}
case <- list(
  param = 1,
  B = B,
  n = 1000, # sample size
  dnull = function(x, param) 
    dexp(x, param),  
  pnull = function(x, param) 
    pexp(x, param),  
  rnull = function(n) rexp(n, 1),
  qnull = function(p) qexp(p, 1), 
  LR = c(0, Inf)
)
case <- make.case(case)
mle.fun <- function(x) 1/mean(x)
```

-  Power vs. various alternatives:

```{r fig7, cache=TRUE}
rn <- 1
out <- matrix(0, 20, length(Methods))
sigma <- round(seq(1, 0.3, length=20), 2)
rownames(out) <- sigma
colnames(out) <- Methods
for(i in 1:20) {
  case$palt = function(x) {
   0.9*pexp(x, 1) + 
   0.1*(pnorm(x, 1.5, sigma[i])-pnorm(0, 1.5,  sigma[i]))/(1-pnorm(0, 1.5, sigma[i]))
  }
  case$ralt = function(n) {
    z <- sample(0:1, case$n, 
                replace = TRUE, prob=c(9,1))
    y <- rnorm(10*case$n, 1.5, sigma[i])
    y <- y[y>0][1:case$n]
    ifelse(z==0, rexp(case$n, 1), y)
  }
  out[i, ] <- 
    tests.power(case, est.mle=mle.fun)  
} 
out <- round(out*100, 1)
```



-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```


```{r}
colnames(out) <- Methods
rownames(out) <- paste("sd =", round(sigma, 2))
df <- data.frame(
  x=rep(sigma, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab(expression(sigma)) +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig7.eps"))
all.cases <- rbind(all.cases, out)
```


-  Does $M_{k,\kappa}$ yield best power?

```{r fig7a, cache=TRUE}
case$palt <- function(x) {
   0.9*pexp(x, 1) + 
   0.1*(pnorm(x, 1.5, 0.74)-pnorm(0, 1.5,  0.74))/(1-pnorm(0, 1.5, 0.74))
  }
case$ralt <- function(n) {
    z <- sample(0:1, case$n, 
                replace = TRUE, prob=c(9, 1))
    y <- rnorm(10*case$n, 1.5, 0.74)
    y <- y[y>0][1:case$n]
    ifelse(z==0, rexp(case$n, 1), y)
  }
case <- make.case(case)
best <- RG.power(case)
Ks <- best$nbins + (-2):2
Ks <- Ks[Ks>1+length(case$param)]
kappa <- 0:4/4
out <- matrix(0, length(Ks), 5)
colnames(out) <- kappa
rownames(out) <- Ks
for(i in seq_along(Ks)) 
     out[i, ] <- standard.chisq.power(case, 
          k=Ks[i],  kappa=kappa,
          method=best$method)$power
unlist(best)
round(out*100, 1)

```

Yes (within simulation error)!


-  Dependence on Sample Size

```{r fig7b, cache=TRUE}
n <- c(100, 250, 500, 1000, 2000)
out <- matrix(0, 2, 5)
dimnames(out) <- list(c("nbins", "kappa"), n)
for(i in c(1, 10, 20)) {
  cat("sigma= ", sigma[i],"\n")
  case$palt <- function(x) {
   0.9*pexp(x, 1) + 
   0.1*(pnorm(x, 1.5, 0.74)-pnorm(0, 1.5,  0.74))/(1-pnorm(0, 1.5, 0.74))
  }
  case$ralt = function(n) {
    z <- sample(0:1, case$n, 
                replace = TRUE, prob=c(9,1))
    y <- rnorm(10*case$n, 1.5, sigma[1])
    y <- y[y>0][1:case$n]
    ifelse(z==0, rexp(case$n, 1), y)
  }
  for(j in seq_along(n)) {
    case$n <- n[j]
    out[, j] <- as.numeric(unlist(RG.power(case))[1:2])
  }
  print(out)
}
```

## Uniform[0,1] vs Beta(1, q)

```{r}
case <- list(
  param = NULL,
  B = B,
  n = 1000, # sample size
  dnull = function(x, param) 
    dunif(x),  
  pnull = function(x, param) 
    punif(x),  
  rnull = function(n) runif(n),
  qnull = function(p) p, 
  palt = function(x) pbeta(x, 1, 1),
  ralt = function(n) rbeta(n, 1, 1),
  LR = c(0, 1)
)
case <- make.case(case)
```


```{r fig8, cache=TRUE}
rn <- 1
out <- matrix(0, 20, length(Methods))
q <- sort(c(1, seq(0.8, 1.2, length=19)))
rownames(out) <- paste("q =", q)
colnames(out) <- Methods
for(i in 1:20) {
  case$palt <- function(x) pbeta(x, 1, q[i])
  case$ralt <- function(n) rbeta(n, 1, q[i])
  out[i, ] <- tests.power(case)  
} 
out <- round(out*100, 1)
```


-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```


```{r}
q <- sort(c(1, seq(0.8, 1.2, length=19)))
rownames(out) <- paste("q =", round(q, 2))
colnames(out) <- Methods
df <- data.frame(
  x=rep(q, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab("q") +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig8.eps"))
out
all.cases <- rbind(all.cases, out)
```


## Uniform[0,1] vs Beta(q, q)

```{r}
case <- list(
  param = NULL,
  B = B,
  n = 1000, # sample size
  dnull = function(x, param) 
    dunif(x),  
  pnull = function(x, param) 
    punif(x),  
  rnull = function(n) runif(n),
  qnull = function(p) p, 
  palt = function(x) pbeta(x, 1, 1),
  ralt = function(n) rbeta(n, 1, 1),
  LR = c(0, 1)
)
case <- make.case(case)
```


```{r fig9, cache=TRUE}
rn <- 1
out <- matrix(0, 20, length(Methods))
q <- sort(c(1, seq(0.8, 1.2, length=19)))
rownames(out) <- paste("q =", q)
colnames(out) <- Methods
for(i in 1:20) {
  case$palt <- function(x) pbeta(x, q[i], q[i])
  case$ralt <- function(n) rbeta(n, q[i], q[i])
  out[i, ] <- tests.power(case)  
} 
out <- round(out*100, 1)
```


-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```


```{r}
q <- sort(c(1, seq(0.8, 1.2, length=19)))
rownames(out) <- paste("q =", round(q, 2))
colnames(out) <- Methods
df <- data.frame(
  x=rep(q, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab("q") +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig9.eps"))
all.cases <- rbind(all.cases, out)
```



## Normal(r, $\sqrt{r}$) vs Gamma(r, 1)

```{r}
case <- list(
  param = NULL,
  B = B,
  n = 1000, # sample size
  dnull = function(x, param) dnorm(x),  
  pnull = function(x, param) pnorm(x),  
  rnull = function(n, param) rnorm(n),
  palt = function(x) pgamma(x, 1, 1),
  ralt = function(n) rgamma(n, 1, 1),
  LR = c(-Inf, Inf)
)
case <- make.case(case)
```


```{r fig10, cache=TRUE}
rn <- 1
out <- matrix(0, 20, length(Methods))
r <- 2*1:20+3
rownames(out) <- paste("r =", r)
colnames(out) <- Methods
for(i in 1:20) {
  case$dnull <- function(x, param) 
    dnorm(x, r[i], sqrt(r[i]))
  case$pnull <- function(x, param) 
    pnorm(x, r[i], sqrt(r[i]))
  case$qnull <- function(p) qnorm(p, r[i], sqrt(r[i]))
  case$rnull <- function(n) rnorm(n, r[i], sqrt(r[i]))
  case$palt <- function(x) pgamma(x, r[i], 1)
  case$ralt <- function(n) rgamma(n, r[i], 1)
  out[i, ] <- tests.power(case)  
} 
out <- round(out*100, 1)
```

-  Mean Powers, in order:

```{r}
z <- sort(round(apply(out, 2, mean)), 
          decreasing = TRUE)
paste0(names(z), ": ", as.numeric(z), "%", collapse = ", ")
```


```{r}
colnames(out) <- Methods
df <- data.frame(
  x=rep(3*r, length(Methods)),
  Power=c(out),
  Method=factor(rep(colnames(out), each=20),
        levels=Methods,
        ordered=TRUE
  )
)
df1 <- df[df$Method=="RG", ]
ggplot(data=df, 
       aes(x, Power , shape=Method)) +
  geom_point() +
  xlab("r") +
  geom_line(data=df1, aes(x, Power)) +
  scale_shape_discrete(
    labels = c(bttr, Methods[-1])) +
  scale_shape_manual(values=custom.shape)
ggsave(paste0(getwd(), "/Computational Statistics/Fig10.eps"))
all.cases <- rbind(all.cases, out)
```


## Type I error


- Uniform [0, 1]

```{r nullU01, cache=TRUE}
rn <- 1
case <- list(
   param = NULL,
   B = 10000,
   n = 1000, # sample size,
   alpha = c(0.01, 0.05, 0.1),
   dnull = function(x, param) dunif(x),  
   pnull = function(x, param) punif(x),
   rnull = function(n) runif(n),
   palt = function(x) punif(x),
   ralt = function(n) runif(n),
   LR = c(0, 1)
)
case <- make.case(case)
out <- RG.power(case)$power
```

- Beta (2, 4)

```{r nullBeta24, cache=TRUE}
rn <- 1
case <- list(
   param = NULL,
   B = 10000,
   n = 1000, # sample size
   alpha = c(0.01, 0.05, 0.1),
   dnull = function(x, param) dbeta(x, 2, 4),  
   pnull = function(x, param) pbeta(x, 2, 4),  
   rnull = function(n) rbeta(n, 2, 4),  
   palt = function(x) pbeta(x, 2, 4),  
   ralt = function(n) rbeta(n, 2, 4), 
   LR = c(0, 1)
)
case <- make.case(case)
tmp <- RG.power(case)$power
out <- rbind("U[0,1]"=out, "Beta(2,4)"=tmp)
colnames(out) <- case$alpha
```

- Gamma (3, 0.5)

```{r nullG30.5, cache=TRUE}
rn  <- 1
case <- list(
   param = NULL,
   B = 10000,
   n = 1000, # sample size
   alpha = c(0.01, 0.05, 0.1),
   dnull = function(x, param) dgamma(x, 3, 0.5),  
   pnull = function(x, param) pgamma(x, 3, 0.5),  
   rnull = function(n) rgamma(n, 3, 0.5),  
   palt = function(x) pgamma(x, 3, 0.5),  
   ralt = function(n) rgamma(n, 3, 0.5), 
   LR = c(0, Inf)
)
case <- make.case(case)
tmp <- RG.power(case)$power
out <- rbind(out, "Gamma(3, 0.5)"=tmp)
```


- Normal(0, 1)

```{r nullN01, cache=TRUE}
rn  <- 1
case <- list(
   param = NULL,
   B = 10000,
   n = 1000, # sample size
   alpha = c(0.01, 0.05, 0.1),
   dnull = function(x, param) dnorm(x),  
   pnull = function(x, param) pnorm(x),
   rnull = function(n) rnorm(n),
   palt = function(x) pnorm(x),
   ralt = function(n) rnorm(n),
   LR = c(-Inf, Inf)
)
case <- make.case(case)
mle.fun <- function(x) c(0, 1)
tmp <- RG.power(case)$power
out <- rbind(out, "N(0,1)"=tmp)
```

- Normal

```{r nullN, cache=TRUE}
rn  <- 1
case <- list(
   param = c(0, 1),
   B = 10000,
   n = 1000, # sample size
   alpha = c(0.01, 0.05, 0.1),   
   dnull = function(x, param) dnorm(x, param[1], param[2]),  
   pnull = function(x, param) pnorm(x, param[1], param[2]),
   rnull = function(n) rnorm(n),
   palt = function(x) pnorm(x),
   ralt = function(n) rnorm(n),
   LR = c(-Inf, Inf)
)
case <- make.case(case)
mle.fun <- function(x) c(mean(x), sd(x))
tmp <- RG.power(case)$power
out <- rbind(out, "Normal"=tmp)
```

- Exponential 1

```{r nullE1, cache=TRUE}
rn  <- 1
case <- list(
   param = NULL,
   B = 10000,
   n = 1000, # sample size
   alpha = c(0.01, 0.05, 0.1),   
   dnull = function(x, param) dexp(x, 1),  
   pnull = function(x, param) pexp(x, 1),
   rnull = function(n) rexp(n, 1),
   palt = function(x) pexp(x, 1),
   ralt = function(n) rexp(n, 1),
   LR = c(0, Inf)
)
case <- make.case(case)
mle.fun <- function(x) c(1)
tmp <- RG.power(case)$power
out <- rbind(out, "Exp(1)"=tmp)
```

- Exponential 

```{r nullE, cache=TRUE}
rn  <- 1
case <- list(
   param = 1,
   B = 10000,
   n = 1000, # sample size
   alpha = c(0.01, 0.05, 0.1),   
   dnull = function(x, param) dexp(x, param),  
   pnull = function(x, param) pexp(x, param),
   rnull = function(n) rexp(n, 1),
   palt = function(x) pexp(x, 1),
   ralt = function(n) rexp(n, 1),
   LR = c(0, Inf)
)
case <- make.case(case)
mle.fun <- function(x) c(1/mean(x))
tmp <- RG.power(case)$power
out <- rbind(out, "Exponential"=tmp)
```

```{r}
out <- round(100*out, 2)
colnames(out) <- c("1%", "5%", "10%")
kable.nice(out, n)
```


## Overall performance

```{r Performance}
m <- nrow(all.cases)
round(sort(apply(all.cases, 2, mean)), 1)
apply(all.cases, 2, fivenum)
```

